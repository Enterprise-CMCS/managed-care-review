name: CDK Deploy

on:
  push:
    branches: 
      - main
    paths:
      - 'services/infra-cdk/**'
      - 'services/app-web/**'
      - '.github/workflows/cdk-deploy.yml'
  pull_request:
    branches:
      - main
    paths:
      - 'services/infra-cdk/**'
      - 'services/app-web/**'
      - '.github/workflows/cdk-deploy.yml'
  workflow_dispatch:
    inputs:
      stage:
        description: 'Stage to deploy'
        required: true
        type: choice
        options:
          - dev
          - val
          - prod
        default: dev

env:
  AWS_REGION: us-east-1
  NODE_VERSION: 20
  STAGE: ${{ github.event.inputs.stage || (github.ref_name == 'main' && 'prod' || 'dev') }}
  NR_LICENSE_KEY: ${{ secrets.NR_LICENSE_KEY }}

# Prevent parallel deployments
concurrency:
  group: cdk-deploy-${{ github.ref }}-${{ github.event.inputs.stage || 'auto' }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read
  pull-requests: write

jobs:
  deploy:
    name: ${{ github.event_name == 'pull_request' && 'CDK Diff' || 'Deploy CDK Infrastructure' }}
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.stage || (github.ref_name == 'main' && 'prod' || 'dev') }}
    outputs:
      api-url: ${{ steps.export-config.outputs.api-url }}
      cognito-region: ${{ steps.export-config.outputs.cognito-region }}
      cognito-user-pool-id: ${{ steps.export-config.outputs.cognito-user-pool-id }}
      cognito-client-id: ${{ steps.export-config.outputs.cognito-client-id }}
      s3-documents-bucket: ${{ steps.export-config.outputs.s3-documents-bucket }}
      s3-qa-bucket: ${{ steps.export-config.outputs.s3-qa-bucket }}
      application-endpoint: ${{ steps.export-config.outputs.application-endpoint }}
      storybook-endpoint: ${{ steps.export-config.outputs.storybook-endpoint }}
    
    steps:
    # 1. Setup environment
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need full history for accurate change detection

    - name: Setup pnpm
      uses: pnpm/action-setup@v4
      with:
        version: 9
        run_install: false

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'pnpm'
        cache-dependency-path: services/infra-cdk/pnpm-lock.yaml

    - name: Configure pnpm and git for HTTPS
      run: |
        pnpm config set git-prefer-https true
        git config --global url."https://github.com/".insteadOf "git@github.com:"

    # 2. Cache dependencies
    - name: Get pnpm store directory
      id: pnpm-cache
      shell: bash
      run: |
        echo "STORE_PATH=$(pnpm store path)" >> $GITHUB_OUTPUT

    - name: Cache pnpm store
      uses: actions/cache@v4
      with:
        path: |
          ${{ steps.pnpm-cache.outputs.STORE_PATH }}
          ~/.cache/prisma
        key: ${{ runner.os }}-pnpm-cdk-${{ hashFiles('services/infra-cdk/pnpm-lock.yaml') }}
        restore-keys: |
          ${{ runner.os }}-pnpm-cdk-

    # 3. Install and build dependencies needed for layer optimization
    - name: Install dependencies for code generation
      run: pnpm install --frozen-lockfile --filter "./packages/**" --filter "./services/app-graphql" --filter "./services/app-proto" --filter "./services/app-api" --filter "./services/app-web"

    - name: Generate code (GraphQL, Prisma, Proto)
      run: pnpm -r generate

    - name: Build packages
      run: pnpm build:packages

    - name: Install CDK dependencies
      working-directory: services/infra-cdk
      run: pnpm install --frozen-lockfile

    # 4. Configure AWS credentials via OIDC
    - name: Validate AWS Account Secrets
      run: |
        if [[ -z "${{ secrets.DEV_AWS_ACCOUNT_ID }}" ]]; then
          echo "ERROR: DEV_AWS_ACCOUNT_ID secret is not configured"
          echo "Please add the following secrets to the repository:"
          echo "  - DEV_AWS_ACCOUNT_ID"
          echo "  - VAL_AWS_ACCOUNT_ID"
          echo "  - PROD_AWS_ACCOUNT_ID"
          exit 1
        fi

    - name: Set AWS Account ID
      id: set-account-id
      run: |
        if [[ "${{ env.STAGE }}" == "prod" ]]; then
          echo "account-id=${{ secrets.PROD_AWS_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
        elif [[ "${{ env.STAGE }}" == "val" ]]; then
          echo "account-id=${{ secrets.VAL_AWS_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
        else
          echo "account-id=${{ secrets.DEV_AWS_ACCOUNT_ID }}" >> $GITHUB_OUTPUT
        fi

    - name: Configure AWS credentials
      uses: ./.github/actions/get_aws_credentials
      with:
        region: ${{ env.AWS_REGION }}
        account-id: ${{ steps.set-account-id.outputs.account-id }}
        stage-name: ${{ env.STAGE == 'dev' && 'main' || env.STAGE }}

    # 5. Build Optimized Lambda Layers
    - name: Build Optimized Lambda Layers
      working-directory: services/infra-cdk
      run: |
        echo "Building optimized Lambda layers with size limits..."
        # Build all layers with aggressive size optimization
        ./scripts/build-layer.sh all
        
        # Verify all layers are under size limits
        echo "Layer sizes:"
        du -sh lambda-layers-*/nodejs.tar.gz 2>/dev/null || true
        
        # Create artifacts directory
        mkdir -p layer-artifacts
        
        # Copy compressed layers to artifacts directory
        cp lambda-layers-prisma-client-engine/nodejs.tar.gz layer-artifacts/prisma-engine-layer.tar.gz
        cp lambda-layers-prisma-client-migration/nodejs.tar.gz layer-artifacts/prisma-migration-layer.tar.gz
        cp lambda-layers-postgres-tools/nodejs.tar.gz layer-artifacts/postgres-tools-layer.tar.gz
        
        echo "âœ… All layers built and ready for deployment"

    # 5a. Test Layer Sizes (Regression Prevention)
    - name: Test Layer Sizes
      working-directory: services/infra-cdk
      run: |
        echo "Testing layer sizes to prevent deployment failures..."
        pnpm run test:size

    # 5b. Upload Layer Artifacts
    - name: Upload Lambda Layer Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: lambda-layers-${{ env.STAGE }}
        path: services/infra-cdk/layer-artifacts/
        retention-days: 7
        compression-level: 0  # Already compressed tar.gz files

    # 6. CDK Synth - Validate infrastructure code
    - name: CDK Synth
      working-directory: services/infra-cdk
      run: |
        echo "Running CDK synth to validate infrastructure..."
        pnpm cdk synth --all --context stage=${{ env.STAGE }} > cdk-synth-output.yaml

    # 7. Store CDK Synth Artifacts
    - name: Store CDK Synth Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: cdk-synth-output-${{ env.STAGE }}
        path: services/infra-cdk/cdk-synth-output.yaml
        retention-days: 5

    # 8. CDK Diff - Check infrastructure changes
    - name: CDK Diff
      id: cdk-diff
      working-directory: services/infra-cdk
      run: |
        echo "Running CDK diff to check for infrastructure changes..."
        
        # Create directory for outputs
        mkdir -p tmp
        DIFF_OUTPUT="tmp/cdk-diff-output.txt"
        
        # Run diff for all stacks, capture output
        pnpm cdk diff --all --context stage=${{ env.STAGE }} | tee "$DIFF_OUTPUT" || true
        
        # Check if there are any differences
        if grep -q "Stack MCR-.* contains changes" "$DIFF_OUTPUT"; then
          echo "has_diff=true" >> $GITHUB_OUTPUT
        else
          echo "has_diff=false" >> $GITHUB_OUTPUT
        fi
        
        # Create markdown summary
        cat > diff-summary.md << EOL
        ## ðŸ” CDK Infrastructure Changes
        
        ### Stage: ${{ env.STAGE }}
        
        <details>
        <summary>Click to expand diff details</summary>
        
        \`\`\`diff
        $(cat "$DIFF_OUTPUT")
        \`\`\`
        
        </details>
        EOL

    # 8. Store CDK Diff Artifacts
    - name: Store CDK Diff Artifacts
      uses: actions/upload-artifact@v4
      with:
        name: cdk-diff-output-${{ env.STAGE }}
        path: |
          services/infra-cdk/tmp/cdk-diff-output.txt
          services/infra-cdk/diff-summary.md
        retention-days: 5

    # 9. Comment PR with CDK Diff
    - name: Comment PR with CDK Diff
      if: github.event_name == 'pull_request' && steps.cdk-diff.outputs.has_diff == 'true'
      uses: actions/github-script@v7
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          const diffContent = fs.readFileSync('services/infra-cdk/diff-summary.md', 'utf8');
          
          // Find existing CDK diff comment
          const comments = await github.rest.issues.listComments({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo
          });
          
          const cdkDiffComment = comments.data.find(comment => 
            comment.body.includes('ðŸ” CDK Infrastructure Changes')
          );
          
          if (cdkDiffComment) {
            // Update existing comment
            await github.rest.issues.updateComment({
              comment_id: cdkDiffComment.id,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: diffContent
            });
          } else {
            // Create new comment
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: diffContent
            });
          }

    # 10. Add CDK Diff to Job Summary
    - name: Add CDK Diff to Job Summary
      if: steps.cdk-diff.outputs.has_diff == 'true'
      run: |
        echo "## ðŸ” CDK Infrastructure Changes Detected" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "Infrastructure changes will be applied during deployment." >> $GITHUB_STEP_SUMMARY
        echo "See the CDK Diff artifact for detailed changes." >> $GITHUB_STEP_SUMMARY

    # 11. CDK Bootstrap (if needed)
    # - name: CDK Bootstrap
    #   working-directory: services/infra-cdk
    #   run: |
    #     pnpm cdk bootstrap aws://${{ steps.set-account-id.outputs.account-id }}/${{ env.AWS_REGION }} \
    #       --cloudformation-execution-policies arn:aws:iam::aws:policy/AdministratorAccess \
    #       -c stage=${{ env.STAGE }} || true

    # 12. Deploy OIDC stack (one-time)
    # COMMENTED OUT: Using existing serverless OIDC setup instead of CDK's GitHubOidcStack
    # to avoid duplicate OIDC providers (only one allowed per AWS account)
    # - name: Deploy GitHub OIDC Stack
    #   if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
    #   working-directory: services/infra-cdk
    #   run: |
    #     pnpm cdk deploy MCR-GitHubOIDC-cdk \
    #       --require-approval never \
    #       --ci

    # 12a. Download Layer Artifacts for Deployment
    - name: Download Lambda Layer Artifacts
      uses: actions/download-artifact@v4
      with:
        name: lambda-layers-${{ env.STAGE }}
        path: services/infra-cdk/layer-artifacts/

    # 12b. Prepare Layer Assets for CDK
    - name: Prepare Layer Assets for CDK
      working-directory: services/infra-cdk
      run: |
        echo "Preparing layer assets for CDK deployment..."
        
        # Extract layers to expected directories
        mkdir -p lambda-layers-prisma-client-engine/nodejs
        mkdir -p lambda-layers-prisma-client-migration/nodejs
        mkdir -p lambda-layers-postgres-tools/nodejs
        
        # Extract artifacts to correct locations
        tar -xzf layer-artifacts/prisma-engine-layer.tar.gz -C lambda-layers-prisma-client-engine/
        tar -xzf layer-artifacts/prisma-migration-layer.tar.gz -C lambda-layers-prisma-client-migration/
        tar -xzf layer-artifacts/postgres-tools-layer.tar.gz -C lambda-layers-postgres-tools/
        
        # Verify extractions
        echo "Layer asset sizes:"
        du -sh lambda-layers-*/nodejs 2>/dev/null || true
        
        echo "âœ… Layer assets prepared for CDK deployment"

    # 13. Deploy All Infrastructure Stacks (explicit order, excluding Frontend)
    - name: Deploy Infrastructure Stacks
      working-directory: services/infra-cdk
      run: |
        # Deploy infrastructure stacks in dependency order (excluding frontend)
        # This ensures proper deployment separation and avoids --exclude issues
        pnpm cdk deploy \
          MCR-Foundation-${{ env.STAGE }}-cdk \
          MCR-Network-${{ env.STAGE }}-cdk \
          MCR-LambdaLayers-${{ env.STAGE }}-cdk \
          MCR-Data-${{ env.STAGE }}-cdk \
          MCR-Auth-${{ env.STAGE }}-cdk \
          MCR-DatabaseOps-${{ env.STAGE }}-cdk \
          MCR-ApiCompute-${{ env.STAGE }}-cdk \
          MCR-Monitoring-${{ env.STAGE }}-cdk \
          --require-approval never \
          --ci \
          -c stage=${{ env.STAGE }}

    # 15. Export infrastructure outputs for frontend build
    - name: Export Infrastructure Outputs
      id: infra-outputs
      run: |
        # Create script to export infrastructure outputs
        cat > export-infra-outputs.sh << 'EOF'
        #!/bin/bash
        set -e
        
        STAGE=$1
        
        # Function to get stack output
        get_output() {
          local stack=$1
          local output_key=$2
          aws cloudformation describe-stacks \
            --stack-name "$stack" \
            --query "Stacks[0].Outputs[?OutputKey=='$output_key'].OutputValue" \
            --output text 2>/dev/null || echo ""
        }
        
        # Export all infrastructure outputs
        API_URL=$(get_output "MCR-ApiCompute-$STAGE-cdk" "ApiUrl")
        USER_POOL_ID=$(get_output "MCR-Auth-$STAGE-cdk" "UserPoolId")
        USER_POOL_CLIENT_ID=$(get_output "MCR-Auth-$STAGE-cdk" "UserPoolClientId")
        IDENTITY_POOL_ID=$(get_output "MCR-Auth-$STAGE-cdk" "IdentityPoolId")
        DOCUMENTS_BUCKET=$(get_output "MCR-Data-$STAGE-cdk" "DocumentUploadsBucketName")
        QA_BUCKET=$(get_output "MCR-Data-$STAGE-cdk" "QAUploadsBucketName")
        
        # Construct user pool domain (matching serverless pattern)
        USER_POOL_DOMAIN="${STAGE}-login-${USER_POOL_CLIENT_ID}.auth.${AWS_REGION}.amazoncognito.com"
        
        # Output for GitHub Actions
        echo "api-url=$API_URL" >> $GITHUB_OUTPUT
        echo "user-pool-id=$USER_POOL_ID" >> $GITHUB_OUTPUT
        echo "user-pool-client-id=$USER_POOL_CLIENT_ID" >> $GITHUB_OUTPUT
        echo "user-pool-domain=$USER_POOL_DOMAIN" >> $GITHUB_OUTPUT
        echo "identity-pool-id=$IDENTITY_POOL_ID" >> $GITHUB_OUTPUT
        echo "documents-bucket=$DOCUMENTS_BUCKET" >> $GITHUB_OUTPUT
        echo "qa-bucket=$QA_BUCKET" >> $GITHUB_OUTPUT
        EOF
        
        chmod +x export-infra-outputs.sh
        ./export-infra-outputs.sh ${{ env.STAGE }}

    # 16. Fetch optional SSM parameters for frontend build
    - name: Fetch SSM Parameters
      id: ssm-params
      run: |
        # Fetch optional parameters from SSM (matching serverless)
        echo "Fetching optional SSM parameters..."
        
        # Helper function to get SSM parameter
        get_ssm_param() {
          local param_name=$1
          aws ssm get-parameter --name "$param_name" --query 'Parameter.Value' --output text 2>/dev/null || echo ""
        }
        
        # Fetch parameters
        LD_CLIENT_ID=$(get_ssm_param "/configuration/react_app_ld_client_id_feds")
        NR_ACCOUNT_ID=$(get_ssm_param "/configuration/react_app_nr_account_id")
        NR_AGENT_ID=$(get_ssm_param "/configuration/react_app_nr_agent_id")
        NR_LICENSE_KEY=$(get_ssm_param "/configuration/react_app_nr_license_key")
        NR_TRUST_KEY=$(get_ssm_param "/configuration/react_app_nr_trust_key")
        
        # Export as environment variables for next step
        echo "VITE_APP_LD_CLIENT_ID=$LD_CLIENT_ID" >> $GITHUB_ENV
        echo "VITE_APP_NR_ACCOUNT_ID=$NR_ACCOUNT_ID" >> $GITHUB_ENV
        echo "VITE_APP_NR_AGENT_ID=$NR_AGENT_ID" >> $GITHUB_ENV
        echo "VITE_APP_NR_LICENSE_KEY=$NR_LICENSE_KEY" >> $GITHUB_ENV
        echo "VITE_APP_NR_TRUST_KEY=$NR_TRUST_KEY" >> $GITHUB_ENV

    # 17. Build frontend assets with real infrastructure configuration
    - name: Build Frontend with Infrastructure Configuration
      working-directory: services/app-web
      env:
        # Match serverless environment variables exactly
        VITE_APP_AUTH_MODE: AWS_COGNITO
        VITE_APP_API_URL: ${{ steps.infra-outputs.outputs.api-url }}
        VITE_APP_APPLICATION_ENDPOINT: https://${{ env.STAGE == 'prod' && 'app' || env.STAGE }}.mcr.cms.gov
        VITE_APP_COGNITO_REGION: ${{ env.AWS_REGION }}
        VITE_APP_COGNITO_ID_POOL_ID: ${{ steps.infra-outputs.outputs.identity-pool-id }}
        VITE_APP_COGNITO_USER_POOL_ID: ${{ steps.infra-outputs.outputs.user-pool-id }}
        VITE_APP_COGNITO_USER_POOL_CLIENT_ID: ${{ steps.infra-outputs.outputs.user-pool-client-id }}
        VITE_APP_COGNITO_USER_POOL_CLIENT_DOMAIN: ${{ steps.infra-outputs.outputs.user-pool-domain }}
        VITE_APP_S3_REGION: ${{ env.AWS_REGION }}
        VITE_APP_S3_DOCUMENTS_BUCKET: ${{ steps.infra-outputs.outputs.documents-bucket }}
        VITE_APP_S3_QA_BUCKET: ${{ steps.infra-outputs.outputs.qa-bucket }}
        VITE_APP_STAGE_NAME: ${{ env.STAGE }}
        VITE_APP_OTEL_COLLECTOR_URL: ${{ steps.infra-outputs.outputs.api-url }}/otel
        # Optional environment variables from SSM (will be fetched in build step)
        VITE_APP_LD_CLIENT_ID: ${{ env.VITE_APP_LD_CLIENT_ID || '' }}
        VITE_APP_NR_ACCOUNT_ID: ${{ env.VITE_APP_NR_ACCOUNT_ID || '' }}
        VITE_APP_NR_AGENT_ID: ${{ env.VITE_APP_NR_AGENT_ID || '' }}
        VITE_APP_NR_LICENSE_KEY: ${{ env.VITE_APP_NR_LICENSE_KEY || '' }}
        VITE_APP_NR_TRUST_KEY: ${{ env.VITE_APP_NR_TRUST_KEY || '' }}
      run: |
        echo "Building frontend assets with infrastructure configuration..."
        pnpm build
        echo "Building Storybook..."
        pnpm storybook:build

    # 18. Deploy Frontend Stack (Final Phase - Independent Deployment)
    - name: Deploy Frontend Stack Only
      working-directory: services/infra-cdk
      run: |
        echo "Deploying Frontend stack independently with CDK native asset management..."
        pnpm cdk deploy MCR-Frontend-${{ env.STAGE }}-cdk \
          --require-approval never \
          --ci \
          -c stage=${{ env.STAGE }} \
          -c enableAppWebIntegration=true

    # 19. Export all deployment outputs
    - name: Export All Deployment Outputs
      id: export-config
      run: |
        # Create script to export all CloudFormation outputs
        cat > export-outputs.sh << 'EOF'
        #!/bin/bash
        set -e
        
        STAGE=$1
        
        # Function to get stack output
        get_output() {
          local stack=$1
          local output_key=$2
          aws cloudformation describe-stacks \
            --stack-name "$stack" \
            --query "Stacks[0].Outputs[?OutputKey=='$output_key'].OutputValue" \
            --output text 2>/dev/null || echo ""
        }
        
        # Export all deployment outputs
        echo "api-url=$(get_output "MCR-ApiCompute-$STAGE-cdk" "ApiUrl")" >> $GITHUB_OUTPUT
        echo "cognito-region=$AWS_REGION" >> $GITHUB_OUTPUT
        echo "cognito-user-pool-id=$(get_output "MCR-Auth-$STAGE-cdk" "UserPoolId")" >> $GITHUB_OUTPUT
        echo "cognito-client-id=$(get_output "MCR-Auth-$STAGE-cdk" "UserPoolClientId")" >> $GITHUB_OUTPUT
        echo "cognito-client-domain=$(get_output "MCR-Auth-$STAGE-cdk" "UserPoolClientDomain")" >> $GITHUB_OUTPUT
        echo "cognito-identity-pool-id=$(get_output "MCR-Auth-$STAGE-cdk" "IdentityPoolId")" >> $GITHUB_OUTPUT
        echo "s3-documents-bucket=$(get_output "MCR-Data-$STAGE-cdk" "DocumentUploadsBucketName")" >> $GITHUB_OUTPUT
        echo "s3-qa-bucket=$(get_output "MCR-Data-$STAGE-cdk" "QAUploadsBucketName")" >> $GITHUB_OUTPUT
        echo "application-endpoint=$(get_output "MCR-Frontend-$STAGE-cdk" "ApplicationUrl")" >> $GITHUB_OUTPUT
        echo "storybook-endpoint=$(get_output "MCR-Frontend-$STAGE-cdk" "StorybookUrl")" >> $GITHUB_OUTPUT
        EOF
        
        chmod +x export-outputs.sh
        ./export-outputs.sh ${{ env.STAGE }}

    # 20. Output deployment information
    - name: Output Deployment Summary
      if: success()
      run: |
        echo "## ðŸš€ Deployment Successful!" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Environment: ${{ env.STAGE }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "| Service | URL |" >> $GITHUB_STEP_SUMMARY
        echo "|---------|-----|" >> $GITHUB_STEP_SUMMARY
        echo "| Application | https://${{ steps.export-config.outputs.application-endpoint }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Storybook | https://${{ steps.export-config.outputs.storybook-endpoint }} |" >> $GITHUB_STEP_SUMMARY
        echo "| API | ${{ steps.export-config.outputs.api-url }} |" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Build Information" >> $GITHUB_STEP_SUMMARY
        echo "- Commit: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
        echo "- Branch: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY
        echo "- Workflow Run: ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY

    # 21. Output PR summary for diff-only runs
    - name: Output PR Summary
      if: github.event_name == 'pull_request'
      run: |
        echo "## ðŸ“‹ Pull Request Infrastructure Review" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Environment: ${{ env.STAGE }}" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        if [[ "${{ steps.cdk-diff.outputs.has_diff }}" == "true" ]]; then
          echo "âœ… **CDK diff completed successfully**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Infrastructure changes have been detected and posted as a comment on this PR." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "These changes will be applied when this PR is merged to main." >> $GITHUB_STEP_SUMMARY
        else
          echo "âœ… **No infrastructure changes detected**" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "This PR does not include any CDK infrastructure changes." >> $GITHUB_STEP_SUMMARY
        fi
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Note:** Deployment steps are skipped for pull requests. Full deployment will occur after merge to main." >> $GITHUB_STEP_SUMMARY

  # Optional: Run integration tests after deployment
  integration-tests:
    name: Integration Tests
    needs: deploy
    if: success() && github.event_name == 'push' && github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Run integration tests
      run: |
        echo "Running integration tests against ${{ needs.deploy.outputs.application-endpoint }}"
        # Add actual integration test commands here
      env:
        APP_URL: https://${{ needs.deploy.outputs.application-endpoint }}
        API_URL: ${{ needs.deploy.outputs.api-url }}